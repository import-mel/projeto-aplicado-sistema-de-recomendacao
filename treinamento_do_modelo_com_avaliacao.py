# -*- coding: utf-8 -*-
"""treinamento_do_modelo_com_avaliacao.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sl5d7NB5aa_n_yEdOKQGq5mjCT1QjHnQ

# Pré Processamento de Dados

## Import das Bibliotecas
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import html

"""## Carregamento dos Dados"""

df_books_v2 = pd.read_csv('Books.csv')
df_ratings_v2 = pd.read_csv('Ratings.csv')
df_users_v2 = pd.read_csv('Users.csv')

"""## Limpeza e Tratamento nos Dados

##**`df_books`**

### Valores Ausentes
"""

df_books_v2.set_index('ISBN', inplace=True)

df_books_v2[df_books_v2.isnull().any(axis=1)]

df_books_v2.loc['0751352497', 'Book-Author'] = 'Unknown'
df_books_v2.loc['1931696993', 'Publisher'] = 'NovelBooks Inc'
df_books_v2.loc['193169656X', 'Publisher'] = 'Novelbooks Inc'
df_books_v2.loc['9627982032', 'Book-Author'] = 'Larissa Anne Downes'

df_books_v2[df_books_v2.isnull().any(axis=1)]

# Tentar converter a coluna 'Year-Of-Publication' para números
df_books_v2['Year-Of-Publication'] = pd.to_numeric(df_books_v2['Year-Of-Publication'], errors='coerce')

# Verificar linhas onde a conversão falhou (valores NaN)
linhas_com_texto = df_books_v2[df_books_v2['Year-Of-Publication'].isna()]

print("Linhas com texto inválido na coluna 'Year-Of-Publication':")
print(linhas_com_texto)

df_books_v2.loc['078946697X', 'Publisher'] = 'DK Publishing Inc'
df_books_v2.loc['2070426769', 'Publisher'] = 'Gallimard'
df_books_v2.loc['0789466953', 'Publisher'] = 'DK Publishing Inc'

df_books_v2.loc['078946697X', 'Image-URL-L'] = 'https://images.amazon.com/images/P/078946697X.0'
df_books_v2.loc['2070426769', 'Image-URL-L'] = 'https://images.amazon.com/images/P/2070426769.0'
df_books_v2.loc['0789466953', 'Image-URL-L'] = 'https://images.amazon.com/images/P/0789466953.0'

df_books_v2.loc['078946697X', 'Year-Of-Publication'] = '2000'
df_books_v2.loc['2070426769', 'Year-Of-Publication'] = '2003'
df_books_v2.loc['0789466953', 'Year-Of-Publication'] = '2000'

df_books_v2.loc['078946697X', 'Book-Author'] = "Cynthia O'Neill"
df_books_v2.loc['2070426769', 'Book-Author'] = 'Jean-Marie Gustave Le Clézio'
df_books_v2.loc['0789466953', 'Book-Author'] = "Cynthia O'Neill"

df_books_v2[df_books_v2.isnull().any(axis=1)]

"""### Conversão da Coluna `Year-Of-Publication` para o Tipo Data e Ajustes nos Anos Inválidos"""

df_books_v2['Year-Of-Publication'] = pd.to_numeric(df_books_v2['Year-Of-Publication'], errors='coerce')

df_books_v2.info()

df_books_v2['Year-Of-Publication'].unique()

print(f"Quantidade de registros com anos iguais a zero: {df_books_v2[df_books_v2['Year-Of-Publication'] == 0].shape[0]}")
print(f"Quantidade de registros com anos menores que zero: {df_books_v2[df_books_v2['Year-Of-Publication'] < 0].shape[0]}")
print(f"Quantidade de registros com anos maiores que 2025: {df_books_v2[df_books_v2['Year-Of-Publication'] > 2025].shape[0]}")
print(df_books_v2[df_books_v2['Year-Of-Publication'] > 2025])

df_books_v2.loc['0671746103', 'Year-Of-Publication'] = 1991
df_books_v2.loc['0671791990', 'Year-Of-Publication'] = 2003
df_books_v2.loc['0870449842', 'Year-Of-Publication'] = 1999
df_books_v2.loc['0140301690', 'Year-Of-Publication'] = 1950
df_books_v2.loc['0140201092', 'Year-Of-Publication'] = 1950
df_books_v2.loc['0394701658', 'Year-Of-Publication'] = 1959
df_books_v2.loc['3442436893', 'Year-Of-Publication'] = 1996
df_books_v2.loc['0870446924', 'Year-Of-Publication'] = 1999
df_books_v2.loc['0671266500', 'Year-Of-Publication'] = 1961
df_books_v2.loc['0684718022', 'Year-Of-Publication'] = 1970
df_books_v2.loc['068471809X', 'Year-Of-Publication'] = 1937
df_books_v2.loc['0671740989', 'Year-Of-Publication'] = 1991

df_books_v2[df_books_v2['Year-Of-Publication'] > 2025]

df_books_v2['Year-Of-Publication'].unique()

# Antes de converter para o tipo data, converter para tipo int
df_books_v2['Year-Of-Publication'] = df_books_v2['Year-Of-Publication'].astype('Int64')

df_books_v2.info()

df_books_v2['Year-Of-Publication'] = pd.to_datetime(
    df_books_v2['Year-Of-Publication'].astype(str) + '-01-01',
    format='%Y-%m-%d',
    errors='coerce'
)

df_books_v2.info()

print(f"Quantidade de linhas com NaT no ano: {df_books_v2[df_books_v2.isnull().any(axis=1)].shape[0]}")

"""## **`df_users`**"""

print(f"Quantidade de registros na tabela users: {df_users_v2.shape[0]}")
print(f"Quantidade de registros com valores nulos em cada coluna: \n{df_users_v2.isna().sum()}")

df_users_v2['Age'].unique()

usuarios_incoerentes = df_users_v2[(df_users_v2['Age'].isna()) |
                                   (df_users_v2['Age'] == 0) |
                                   (df_users_v2['Age'] > 110)]

usuarios_com_reviews = set(df_ratings_v2['User-ID'])

usuarios_incoerentes_sem_reviews = set(usuarios_incoerentes['User-ID']) - usuarios_com_reviews

df_users_filtrado = df_users_v2[~df_users_v2['User-ID'].isin(usuarios_incoerentes_sem_reviews)]

usuarios_restantes_sem_reviews = set(df_users_filtrado['User-ID']) - usuarios_com_reviews

df_users_v3 = df_users_filtrado[~df_users_filtrado['User-ID'].isin(usuarios_restantes_sem_reviews)]

print(f"Total de usuários antes da filtragem: {df_users_v2.shape[0]}")
print(f"Total de usuários após a filtragem: {df_users_v3.shape[0]}")
print(f"Usuários incoerentes sem reviews removidos: {len(usuarios_incoerentes_sem_reviews)}")
print(f"Usuários válidos sem reviews removidos: {len(usuarios_restantes_sem_reviews)}")
print(f"Total de usuários removidos: {df_users_v2.shape[0] - df_users_v3.shape[0]}")

df_users_v3['Age'].unique()

print(f"Quantidade de registros com idades acima que 110: {df_users_v3[df_users_v3['Age'] > 110].shape[0]}")
print(f"Quantidade de registros com idades iguais a zero: {df_users_v3[df_users_v3['Age'] == 0].shape[0]}")
print(f"Total de linhas que serão alteradas: {df_users_v3[df_users_v3['Age'] > 110].shape[0] + df_users_v3[df_users_v3['Age'] == 0].shape[0]}")

df_users_v3.loc[(df_users_v3['Age'] > 110) | (df_users_v3['Age'] == 0), 'Age'] = np.nan

df_users_v3['Age'].unique()

df_users_v3.info()

df_users_v3['Age'] = df_users_v3['Age'].astype('Int64')

df_users_v3.info()

df_users_v2 = df_users_v3

df_users_v2.shape[0]

localizacoes_codificadas = df_users_v2[df_users_v2['Location'].str.contains('&#', na=False)]
print(localizacoes_codificadas)

# Decodificar as localizações codificadas
df_users_v2['Location'] = df_users_v2['Location'].apply(lambda x: html.unescape(x) if isinstance(x, str) and '&#' in x else x)

# Padronizar as localizações, transformando para minúsculas e removendo espaços extras
df_users_v2['Location'] = df_users_v2['Location'].str.lower().str.strip()

print(df_users_v2[df_users_v2['User-ID'] == 189961])

# Resetar a coluna 'index' do df_books_v2
df_books_v2_reset = df_books_v2.reset_index()

# Renomear a coluna 'index' para 'ISBN' no DataFrame de livros
df_books_v2.rename(columns={'index': 'ISBN'}, inplace=True)

from google.colab import files

# Salvar os DataFrames em arquivos CSV
df_users_v2.to_csv("df_users_v2.csv", index=False)
df_books_v2_reset.to_csv("df_books_v2.csv", index=False)
df_ratings_v2.to_csv("df_ratings_v2.csv", index=False)

"""# Treinamento do Modelo

## Importação das Bibliotecas
"""

pip install scikit-surprise

pip install numpy==1.23.5

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from scipy.sparse import csr_matrix
from surprise import SVD, Dataset, Reader
from surprise.model_selection import cross_validate

"""## Carregamento de Dados"""

df_books_v2 = pd.read_csv('df_books_v2.csv')
df_ratings_v2 = pd.read_csv('df_ratings_v2.csv')
df_users_v2 = pd.read_csv('df_users_v2.csv')

print(f"Colunas do dataframe books: {df_books_v2.columns}\n")
print(f"Colunas do dataframe ratings: {df_ratings_v2.columns}\n")
print(f"Colunas do dataframe users: {df_users_v2.columns}\n")

"""## Filtragem de Usuários por Idade e Localização (País)

### Aplicação de filtros adicionais com avaliações de livros

Este código realiza a filtragem dos dados de usuários, considerando informações de idade e país.

Ele define faixas etárias relevantes e extrai o país da localização para segmentar os usuários.

 As etapas de filtragem incluem:

* **Filtragem por idade**: Remove usuários com idade abaixo de um limite mínimo.
Filtragem por país: Seleciona usuários de países específicos considerados relevantes.
* **Filtragem por atividade do usuário**: Mantém apenas usuários com um número mínimo de avaliações.
* **Filtragem por popularidade do livro:** Inclui apenas livros com um número mínimo de avaliações.

Essas etapas garantem que o sistema de recomendação trabalhe com dados de alta qualidade, focando em usuários ativos e livros populares em regiões relevantes.
"""

# Parâmetros de filtragem
idade_minima = 20  # Define a idade mínima para considerar um usuário relevante (20 anos)
paises_relevantes = ['usa', 'canada', 'uk']  # Lista de países relevantes para o sistema de recomendação

# Tratar valores ausentes na coluna 'Age'
df_users_v2['Age'] = df_users_v2['Age'].fillna(df_users_v2['Age'].mean()) # Preenche valores ausentes na coluna 'Age' com a média de idade

# Filtrar usuários por idade
usuarios_idade_filtrada = df_users_v2[df_users_v2['Age'] >= idade_minima]['User-ID'].unique() # Obtém IDs de usuários com idade igual ou superior à idade mínima
avaliacoes_filtradas = df_ratings_v2[df_ratings_v2['User-ID'].isin(usuarios_idade_filtrada)] # Filtra as avaliações para incluir apenas usuários com idade filtrada

# Filtrar usuários por país (extrair país)
def extrair_pais(location):
    try:
        pais = location.split(',')[-1].strip().lower() # Extrai o país da string de localização, remove espaços e converte para minúsculo
        if pais:
            return pais
        else:
            return None # Retorna None se o país estiver vazio
    except:
        return None # Retorna None em caso de erro ao extrair o país

df_users_v2['Pais'] = df_users_v2['Location'].apply(extrair_pais) # Aplica a função para extrair o país da coluna 'Location' e cria a coluna 'Pais'
usuarios_pais_filtrada = df_users_v2[df_users_v2['Pais'].isin(paises_relevantes)]['User-ID'].unique() # Obtém IDs de usuários dos países relevantes
avaliacoes_filtradas = avaliacoes_filtradas[avaliacoes_filtradas['User-ID'].isin(usuarios_pais_filtrada)] # Filtra as avaliações para incluir apenas usuários dos países filtrados

# Filtrar usuários com um número mínimo de avaliações
minimo_avaliacoes_usuario = 20  # Define o número mínimo de avaliações que um usuário deve ter para ser considerado ativo
contagem_avaliacoes_usuario = avaliacoes_filtradas['User-ID'].value_counts()  # Conta quantas avaliações cada usuário fez
usuarios_ativos = contagem_avaliacoes_usuario[contagem_avaliacoes_usuario >= minimo_avaliacoes_usuario].index  # Obtém os IDs dos usuários ativos
avaliacoes_filtradas = avaliacoes_filtradas[avaliacoes_filtradas['User-ID'].isin(usuarios_ativos)]  # Filtra as avaliações para incluir apenas usuários ativos

# Filtrar livros com um número mínimo de avaliações
minimo_avaliacoes_livro = 20 # Define o número mínimo de avaliações que um livro deve ter para ser considerado popular
contagem_avaliacoes_livro = df_ratings_v2['ISBN'].value_counts() # Conta quantas avaliações cada livro recebeu
livros_populares = contagem_avaliacoes_livro[contagem_avaliacoes_livro >= minimo_avaliacoes_livro].index # Obtém os ISBNs dos livros populares
avaliacoes_filtradas = df_ratings_v2[df_ratings_v2['ISBN'].isin(livros_populares)] # Filtra as avaliações para incluir apenas livros populares

"""## Criação da Matriz de Utilidade
### Conversão para otimização da memória

A matriz de utilidade é uma tabela que mostra as interações entre usuários e itens, onde cada célula contém a avaliação de um usuário para um livro. Ela foi escolhida porque é muito usada em sistemas de recomendação, ajudando a entender as preferências dos usuários e prever quais livros podem interessá-los no futuro, com base nas avaliações passadas.

Este código tem como objetivo criar uma matriz de utilidade a partir dos dados de avaliações filtradas. A matriz de utilidade é uma representação crucial para sistemas de recomendação colaborativos, onde as linhas representam usuários, as colunas representam livros (ISBNs) e os valores representam as avaliações dos usuários para os livros.

A matriz de utilidade foi então convertida para o formato *csr_matrix* (*Compressed Sparse Row matrix*). Este formato é otimizado para matrizes esparsas, que são comuns em sistemas de recomendação onde a maioria dos usuários avaliou apenas uma pequena fração dos livros disponíveis. A conversão para *csr_matrix* reduz o uso de memória e acelera cálculos, tornando o sistema de recomendação mais eficiente.
"""

# Cria a matriz de utilidade a partir das avaliações filtradas, preenchendo valores ausentes com 0
matriz_utilidade = avaliacoes_filtradas.pivot_table(index='User-ID', columns='ISBN', values='Book-Rating').fillna(0)

# Converte a matriz de utilidade para o formato csr_matrix para otimização de memória e cálculos
matriz_utilidade_csr = csr_matrix(matriz_utilidade.values)

print(f"Tamanho da matriz de utilidade filtrada: {matriz_utilidade_csr.shape}")

"""## Treinamento e Avaliação de um Modelo de Recomendação SVD

### Utilizando a Biblioteca Surprise para Sistemas de Recomendação Colaborativos

Este código demonstra o processo de treinamento e avaliação de um modelo de recomendação utilizando o algoritmo *SVD* (*Singular Value Decomposition*) da biblioteca `Surprise`.

O *SVD* é um algoritmo popular para sistemas de recomendação colaborativos, que decompõe a matriz de utilidade em fatores latentes, permitindo prever as avaliações que um usuário daria a um livro.

O código segue as seguintes etapas:

* **Preparação dos dados**: Cria um Reader para definir o formato dos dados de avaliação e carrega os dados filtrados em um objeto Dataset da Surprise.
* **Treinamento do modelo**: Cria uma instância do modelo SVD e o treina com os dados de avaliação.
* **Avaliação do modelo**: Utiliza validação cruzada para avaliar o desempenho do modelo em diferentes partições dos dados.
* **Treinamento final**: Treina o modelo com todos os dados disponíveis para maximizar o aprendizado.

"""

# Criar o Reader para indicar o formato dos dados
reader = Reader(rating_scale=(1, 10)) # Cria um objeto Reader para definir a escala de avaliação (1 a 10)

avaliacoes_filtradas = df_ratings_v2 # Atribui o DataFrame de avaliações filtradas à variável avaliacoes_filtradas

# Criar o dataset a partir do DataFrame filtrado
avaliacoes_dataset = Dataset.load_from_df(avaliacoes_filtradas[['User-ID', 'ISBN', 'Book-Rating']], reader) # Cria um objeto Dataset a partir do DataFrame, especificando as colunas relevantes e o Reader

# Criar o modelo SVD
modelo_svd = SVD() # Cria uma instância do modelo SVD

# Avaliação do modelo com validação cruzada
resultados = cross_validate(modelo_svd, avaliacoes_dataset, cv=5, verbose=True) # Avalia o modelo usando validação cruzada com 5 folds e imprime os resultados

# Treinar o modelo com todos os dados
trainset = avaliacoes_dataset.build_full_trainset() # Cria um objeto Trainset com todos os dados de avaliação
modelo_svd.fit(trainset) # Treina o modelo SVD com o conjunto de treinamento completo

"""### Gerando Recomendações para um Usuário Específico

Este código implementa uma função `recomendar_livros_svd` que gera recomendações de livros personalizadas para um usuário específico, utilizando o modelo *SVD* treinado anteriormente.

A função identifica os livros que o usuário ainda não avaliou, prevê as avaliações que o usuário daria a esses livros e, em seguida, recomenda os livros com as previsões de avaliação mais altas.
"""

def recomendar_livros_svd(id_usuario, df_books_v2, n_recomendacoes=3):
    livros_nao_avaliados = df_books_v2[~df_books_v2['ISBN'].isin(avaliacoes_filtradas[avaliacoes_filtradas['User-ID'] == id_usuario]['ISBN'])]

    # Prever notas para os livros não avaliados
    predicoes = [(isbn, modelo_svd.predict(id_usuario, isbn).est) for isbn in livros_nao_avaliados['ISBN']]

    # Ordenar pelos livros com melhor previsão
    predicoes.sort(key=lambda x: x[1], reverse=True)

    # Selecionar os melhores N livros
    recomendacoes = [df_books_v2[df_books_v2['ISBN'] == isbn]['Book-Title'].values[0] for isbn, _ in predicoes[:n_recomendacoes]]

    return recomendacoes

id_usuario = 99
livros_recomendados = recomendar_livros_svd(id_usuario, df_books_v2)

print(f"Livros recomendados para o usuário {id_usuario}:")
for livro in livros_recomendados:
    print(f"- {livro}")

"""# Interpretação das métricas de validação cruzada com 5 divisões (folds)

* **RMSE (Root Mean Squared Error)**
  * Média (Mean): 3.4971
  * Desvio padrão (Std): 0.0015

O RMSE é uma medida de quão distantes estão as previsões dos valores reais. Quanto menor for o valor de RMSE, melhor. Neste caso, o modelo SVD tem uma boa precisão, com um RMSE consistente entre os folds.

* **MAE (Mean Absolute Error)**
  * Média (Mean): 2.9269
  * Desvio padrão (Std): 0.0029

O MAE mede a média das diferenças absolutas entre as previsões e os valores reais. Menor MAE também indica que as previsões estão mais próximas dos valores reais. O valor de 2.93 sugere uma precisão razoável no modelo, mas ainda há espaço para melhorias.

* **Fit time (Tempo de treinamento)**
  * Média (Mean): 27.53 segundos
  * Desvio padrão (Std): 0.35 segundos

O tempo de treinamento é o tempo necessário para o modelo aprender a partir dos dados. Com base nesses resultados, o tempo de treinamento é estável entre os folds (~27.5s), indicando que a complexidade do treinamento não varia muito

* **Test time (Tempo de teste)**
  * Média (Mean): 2.93 segundos
  * Desvio padrão (Std): 0.32 segundos

O tempo de teste é o tempo necessário para fazer as previsões no conjunto de teste. O modelo leva em média 3 segundos para testar.

# Conclusão
O modelo SVD tem um desempenho bom em termos de RMSE e MAE, com um erro médio relativamente baixo. O tempo de ajuste e teste também são razoáveis, considerando que o modelo foi validado em 5 folds.

Os próximos passos consistem em ajustar os parâmetros do modelo SVD, como n_factors, lr_all, ou reg_all, para melhorar a precisão.
"""